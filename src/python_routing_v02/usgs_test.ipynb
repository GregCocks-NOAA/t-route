{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ql_from_wrf_hydro(qlat_files, index_col=\"station_id\", value_col=\"q_lateral\"):\n",
    "    \"\"\"\n",
    "    qlat_files: globbed list of CHRTOUT files containing desired lateral inflows\n",
    "    index_col: column/field in the CHRTOUT files with the segment/link id\n",
    "    value_col: column/field in the CHRTOUT files with the lateral inflow value\n",
    "\n",
    "    In general the CHRTOUT files contain one value per time step. At present, there is\n",
    "    no capability for handling non-uniform timesteps in the qlaterals.\n",
    "\n",
    "    The qlateral may also be input using comma delimited file -- see\n",
    "    `get_ql_from_csv`\n",
    "    \"\"\"\n",
    "\n",
    "    li = []\n",
    "\n",
    "    for filename in qlat_files:\n",
    "        with xr.open_dataset(filename) as ds:\n",
    "            df1 = ds.to_dataframe()\n",
    "\n",
    "        li.append(df1)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=False)\n",
    "    mod = frame.reset_index()\n",
    "    ql = mod.pivot(index=index_col, columns=\"time\", values=value_col)\n",
    "\n",
    "    return ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if qlat_input_folder:\n",
    "        qlat_files = glob.glob(qlat_input_folder + qlat_file_pattern_filter)\n",
    "        qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "            qlat_files=qlat_files,\n",
    "            index_col=qlat_file_index_col,\n",
    "            value_col=qlat_file_value_col,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(\"/\", \"content\", \"t-route\")\n",
    "\n",
    "        test_folder = pathlib.Path(root, \"test\")\n",
    "        geo_input_folder = test_folder.joinpath(\"input\", \"geo\")\n",
    "\n",
    "    \n",
    "    \n",
    "        forcing_parameters[\"qlat_input_folder\"] = os.path.join(\n",
    "                root,\n",
    "                \"test/input/geo/NWM_2.1_Sample_Datasets/Pocono_TEST1/example_CHRTOUT/\",\n",
    "            )\n",
    "            forcing_parameters[\"qlat_file_pattern_filter\"] = \"/*.CHRTOUT_DOMAIN1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib \n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "qlat_file_index_col = \"feature_id\"\n",
    "qlat_file_value_col = \"q_lateral\"\n",
    "\n",
    "root = pathlib.Path(\"/\", \"t-route_fresh\", \"t-route\")\n",
    "usgs_timeslices_folder = os.path.join(\n",
    "        root,\n",
    "        \"test/input/geo/nudgingTimeSliceObs/\",\n",
    "    )\n",
    "\n",
    "usgs_file_pattern_filter = \"*.usgsTimeSlice.ncdf\"\n",
    "\n",
    "usgs_files = glob.glob(usgs_timeslices_folder + usgs_file_pattern_filter)\n",
    "\n",
    "# usgs_df = get_ql_from_wrf_hydro(\n",
    "#     qlat_files=usgs_files,\n",
    "#     index_col=qlat_file_index_col,\n",
    "#     value_col=qlat_file_value_col,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/t-route_fresh/t-route/test/input/geo/nudgingTimeSliceObs/2020-03-19_18:00:00.15min.usgsTimeSlice.ncdf'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"2020-03-19_18:00:00.15min.usgsTimeSlice.ncdf\"\n",
    "framework_folder + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationId</th>\n",
       "      <th>time</th>\n",
       "      <th>discharge</th>\n",
       "      <th>discharge_quality</th>\n",
       "      <th>queryTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stationIdInd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>b'       08158930'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b'       02336300'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>b'       08086212'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>b'       02215260'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>252.019928</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>b'       02439400'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>58.899040</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3864</td>\n",
       "      <td>b'       00000417'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3865</td>\n",
       "      <td>b'       03353200'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>9.202975</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3866</td>\n",
       "      <td>b'       02303000'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3867</td>\n",
       "      <td>b'       09386950'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3868</td>\n",
       "      <td>b'       05374000'</td>\n",
       "      <td>b'2020-03-19_18:00:00'</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2020-03-19 18:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3869 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       stationId                    time      discharge  \\\n",
       "stationIdInd                                                              \n",
       "0             b'       08158930'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "1             b'       02336300'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "2             b'       08086212'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "3             b'       02215260'  b'2020-03-19_18:00:00'     252.019928   \n",
       "4             b'       02439400'  b'2020-03-19_18:00:00'      58.899040   \n",
       "...                          ...                     ...            ...   \n",
       "3864          b'       00000417'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "3865          b'       03353200'  b'2020-03-19_18:00:00'       9.202975   \n",
       "3866          b'       02303000'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "3867          b'       09386950'  b'2020-03-19_18:00:00'       0.000000   \n",
       "3868          b'       05374000'  b'2020-03-19_18:00:00' -999999.000000   \n",
       "\n",
       "              discharge_quality           queryTime  \n",
       "stationIdInd                                         \n",
       "0                           100 2020-03-19 18:00:00  \n",
       "1                           100 2020-03-19 18:00:00  \n",
       "2                           100 2020-03-19 18:00:00  \n",
       "3                           100 2020-03-19 18:00:00  \n",
       "4                           100 2020-03-19 18:00:00  \n",
       "...                         ...                 ...  \n",
       "3864                        100 2020-03-19 18:00:00  \n",
       "3865                        100 2020-03-19 18:00:00  \n",
       "3866                        100 2020-03-19 18:00:00  \n",
       "3867                        100 2020-03-19 18:00:00  \n",
       "3868                        100 2020-03-19 18:00:00  \n",
       "\n",
       "[3869 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"/home/jacob.hreha/github/t-route_fresh/t-route/test/input/geo/nudgingTimeSliceObs/\" + file_name)\n",
    "df = ds.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.49 TiB for an array with shape (109223, 3477, 480) and data type |S15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9743ecba0704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/APD/inland_hydraulics/wrf-hydro-run/nudgingLastObs_OUTPUTS/nudgingLastObs.2020-03-20_18:00:00.nc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, dim_order)\u001b[0m\n\u001b[1;32m   4619\u001b[0m         \u001b[0mordered_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_dim_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4621\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4623\u001b[0m     def _set_sparse_data_from_dataframe(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_to_dataframe\u001b[0;34m(self, ordered_dims)\u001b[0m\n\u001b[1;32m   4585\u001b[0m         data = [\n\u001b[1;32m   4586\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4587\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4588\u001b[0m         ]\n\u001b[1;32m   4589\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4585\u001b[0m         data = [\n\u001b[1;32m   4586\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4587\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4588\u001b[0m         ]\n\u001b[1;32m   4589\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mordered_dims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.49 TiB for an array with shape (109223, 3477, 480) and data type |S15"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(\"/home/APD/inland_hydraulics/wrf-hydro-run/nudgingLastObs_OUTPUTS/nudgingLastObs.2020-03-20_18:00:00.nc\")\n",
    "df = ds.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if qlat_input_folder:\n",
    "        qlat_files = glob.glob(qlat_input_folder + qlat_file_pattern_filter)\n",
    "        qlat_df = nio.get_ql_from_wrf_hydro(\n",
    "            qlat_files=qlat_files,\n",
    "            index_col=qlat_file_index_col,\n",
    "            value_col=qlat_file_value_col,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-03-19_18:00:00.15min.usgsTimeSlice.ncdf\n",
    "def get_ql_from_wrf_hydro(qlat_files, index_col=\"station_id\", value_col=\"q_lateral\"):\n",
    "    \"\"\"\n",
    "    qlat_files: globbed list of CHRTOUT files containing desired lateral inflows\n",
    "    index_col: column/field in the CHRTOUT files with the segment/link id\n",
    "    value_col: column/field in the CHRTOUT files with the lateral inflow value\n",
    "\n",
    "    In general the CHRTOUT files contain one value per time step. At present, there is\n",
    "    no capability for handling non-uniform timesteps in the qlaterals.\n",
    "\n",
    "    The qlateral may also be input using comma delimited file -- see\n",
    "    `get_ql_from_csv`\n",
    "    \"\"\"\n",
    "\n",
    "    li = []\n",
    "\n",
    "    for filename in qlat_files:\n",
    "        with xr.open_dataset(filename) as ds:\n",
    "            df1 = ds.to_dataframe()\n",
    "\n",
    "        li.append(df1)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=False)\n",
    "    mod = frame.reset_index()\n",
    "    ql = mod.pivot(index=index_col, columns=\"time\", values=value_col)\n",
    "\n",
    "    return ql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
